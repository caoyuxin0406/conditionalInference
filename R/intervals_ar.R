#' Pivot with Instrument Variables for AR Test Statistic
#'
#' Calculate the pivot quantities of the optimization intervals.
#'
#' @param opt_intervals Optimization intervals
#' @param linear_func Linear function
#' @param parameter_reference Parameter for reference
#' @param candidate Candidate value
#' @param gl_ar The group lasso object for AR test statistic representing the
#'              penalized convex optimization equation (generated by
#'              group_lasso_iv function)
#' @param alternative A list of ['greater', 'less', 'twosided'],
#'                    which indicates what alternative to use
#'
#' @return A pivot quantity.
#' @export
#'
#' @references
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2019). Inference After Selecting
#' Plausibly Valid Instruments with Application to Mendelian Randomization.
#'
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2020). Inferring Treatment
#' Effects After Testing Instrument Strength in Linear Models.
#'
#' @seealso
#' \link{pivot_iv} for calculating the pivot quantities/p-values of the
#' optimization intervals for TSLS test statistic. This process is similar
#' to that of AR test statistic.
#'
#' \link{weights_iv_ar} that computes the weights of candidate pivot values
#' for AR test statistic.
#'
#' \link{test_stat} that returns the result of comparing parameter of
#' interest and observed target test statistic.
#'
#' @examples
#' # Fit the group lasso optimization model for AR statisitc
#' Z = matrix(rnorm(10*3), nrow = 10, ncol = 3) +
#'     matrix(replicate(3, matrix(0, nrow = 10, ncol = 1)),
#'     nrow = 10)
#' errorTerm = MASS::mvrnorm(n=10, mu=rep(0,2),
#'             Sigma=rbind(c(1, 0.8),c(0.8, 1)))
#' D = Z %*% rep(1, 3) + errorTerm[1:10, 2]
#' Y = D * 1 + errorTerm[1:10, 1]
#' gl_ar <- group_lasso_iv_ar(Y, D, Z)
#' model_ar <- fit_ar(gl_ar)
#'
#' # Estimate covariance and obtain summary statistics
#' cov = estimate_covariance(Y, D, Z)
#' s <- summary_ar(gl_ar, model_ar$sampler,
#'                 Sigma_11=cov[1,1], Sigma_12=cov[1,2])
#'
#' # Construct the optimization intervals before computing confidence intervals
#' # for AR test statistic
#' opt_sampling_info = list(sets::tuple(model_ar$sampler,
#'                                      s$opt_sample,
#'                                      s$cov_target,
#'                                      s$cov_target_score))
#' intervals <- optimization_intervals(opt_sampling_info,
#'                                     s$observed_target,
#'                                     nrow(s$opt_sample))
#'
#' # Compute pivot value for AR test statistic
#' pivot_iv_ar(opt_intervals=intervals,
#'             linear_func=s$K2,
#'             parameter_reference=0,
#'             candidate=0,
#'             gl_ar=gl_ar,
#'             alternative='greater')
#'
#' # Compute the pivot value for a sequence of candidate value
#' level = 0.95
#' grid_min = -4000 * 0.5946693  # -how_many_sd * sd(sample_stat)
#' grid_max = 4000 * 0.5946693 # how_many_sd * sd(sample_stat)
#'
#' for (beta in seq(grid_min, grid_max, length.out=10)) {
#'   pivot_iv_ar(opt_intervals=intervals,
#'               linear_func=s$K2,
#'               parameter_reference=s$two_stage_ls[1,1],
#'               candidate=beta,
#'               gl_ar=gl_ar,
#'               alternative='greater') - (1-level) + (1-level)
#' }
pivot_iv_ar <- function(opt_intervals,
                        linear_func,
                        parameter_reference,
                        candidate,
                        gl_ar,
                        alternative='twosided') {

  if (alternative != 'greater' && alternative != 'less' && alternative != 'twosided') {
    print("alternative should be one of ['greater', 'less', 'twosided']")
  }

  observed_target = opt_intervals$observed
  sample_target = opt_intervals$normal_sample

  target_cov = opt_intervals$target_cov

  idx = 1
  for (t in opt_intervals$opt_sampling_info) {
    opt_sampler = t[[1]]
    opt_sample = t[[2]]
    score_cov = t[[4]]

    # score_cov is a 1xp matrix
    cur_score_cov = t(score_cov)

    # cur_nuisance is in the view's score coordinates
    #offset = apply(cur_score_cov, c(1,2), function(x) x * observed_stat / target_cov)
    cur_nuisance = opt_sampler$observed_score_state - cur_score_cov %*%
      solve(target_cov) %*% observed_target # px1 matrix
    cur_translate_dirs = cur_score_cov %*% solve(target_cov)
    cur_translate_dirs_candidate = cur_score_cov %*% solve(target_cov) %*% linear_func

    if (idx == 1) {
      nuisance = list(cur_nuisance)
      translate_dirs = list(cur_translate_dirs)
      translate_dirs_candidate = list(cur_translate_dirs_candidate)
    } else {
      nuisance = append(nuisance, cur_nuisance)
      translate_dirs = append(translate_dirs, cur_translate_dirs)
      translate_dirs_candidate = append(translate_dirs_candidate, cur_translate_dirs_candidate)
    }
    idx = idx + 1
  }

  weights = conditionalInference::weights_iv_ar(opt_intervals,
                                                sample_target,  # normal sample under zero
                                                candidate,      # the difference beta-beta_reference
                                                nuisance,       # nuisance sufficient stats for each view
                                                translate_dirs, # points will be moved like sample * score_cov
                                                translate_dirs_candidate)

  beta = parameter_reference + candidate
  observed_target_beta = observed_target - linear_func*candidate
  observed_stat = conditionalInference::test_stat(gl_ar$Y,
                                                  gl_ar$D,
                                                  gl_ar$Z,
                                                  beta,
                                                  observed_target_beta)
  sample_stat = conditionalInference::test_stat(gl_ar$Y,
                                                gl_ar$D,
                                                gl_ar$Z,
                                                beta,
                                                sample_target)

  comp = apply(sample_stat, c(1,2), function(x) x <= observed_stat)
  pivot = mean(comp * weights) / mean(weights)

  if (alternative == 'twosided') {
    return(2 * min(pivot, 1 - pivot))
  } else if (alternative == 'less') {
    return(pivot)
  } else {
    return(1 - pivot)
  }
}


#' Weights with Instrument Variables for AR Test Statistic
#'
#' Calculate the weights of candidate pivot values for AR test statistic.
#'
#' @param opt_intervals Optimization intervals
#' @param sample_target Normal sample under zero
#' @param candidate The difference beta-beta_reference
#' @param nuisance Nuisance sufficient stats for each view
#' @param translate_dirs Points will be moved like sample * score_cov
#' @param translate_dirs_candidate Candidate for points movement direction
#'
#' @return Weights of the sequence of pivot values
#' @export
#'
#' @references
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2019). Inference After Selecting
#' Plausibly Valid Instruments with Application to Mendelian Randomization.
#'
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2020). Inferring Treatment
#' Effects After Testing Instrument Strength in Linear Models.
#'
#' @seealso
#' \link{log_density} for calculating the log density of a given equation,
#' including the Jacobian term.
#'
#' @examples
#' # Fit the group lasso optimization model for AR statisitc
#' Z = matrix(rnorm(10*3), nrow = 10, ncol = 3) +
#'     matrix(replicate(3, matrix(0, nrow = 10, ncol = 1)),
#'     nrow = 10)
#' errorTerm = MASS::mvrnorm(n=10, mu=rep(0,2),
#'             Sigma=rbind(c(1, 0.8),c(0.8, 1)))
#' D = Z %*% rep(1, 3) + errorTerm[1:10, 2]
#' Y = D * 1 + errorTerm[1:10, 1]
#' gl_ar <- group_lasso_iv_ar(Y, D, Z)
#' model_ar <- fit_ar(gl_ar)
#'
#' # Estimate covariance and obtain summary statistics
#' cov = estimate_covariance(Y, D, Z)
#' s <- summary_ar(gl_ar, model_ar$sampler, Sigma_11=cov[1,1],
#'                 Sigma_12=cov[1,2], ndraw=20, burnin=20)
#'
#' # Construct the optimization intervals before computing confidence
#' #  intervals for AR test statistic
#' opt_sampling_info = list(sets::tuple(model_ar$sampler,
#'                                      s$opt_sample,
#'                                      s$cov_target,
#'                                      s$cov_target_score))
#' intervals <- optimization_intervals(opt_sampling_info,
#'                                     s$observed_target,
#'                                     nrow(s$opt_sample))
#'
#' # Setting up parameters for weights_iv_ar method
#' observed_target = intervals$observed
#' sample_target = intervals$normal_sample
#' target_cov = intervals$target_cov
#' cur_nuisance = matrix(c(-3.473599, -2.994906, -1.232047))
#' cur_translate_dirs = matrix(c(-0.0262027124, 0.0003586071, -0.004356665,
#'                               0.0003586071, -0.0223224489, -0.010211015,
#'                              -0.0043566649, -0.0102110149, -0.021786600),
#'                              nrow=3, ncol=3)
#' cur_translate_dirs_candidate = matrix(c(-0.3205551, -0.2534793, -0.2088712))
#' nuisance = list(cur_nuisance)
#' translate_dirs = list(cur_translate_dirs)
#' translate_dirs_candidate = list(cur_translate_dirs_candidate)
#'
#' # Compute pivot value for AR test statistic
#' weights_iv_ar(opt_intervals=intervals,
#'               sample_target=sample_target,
#'               candidate=0,
#'               nuisance=nuisance,
#'               translate_dirs=translate_dirs,
#'               translate_dirs_candidate=translate_dirs_candidate)
weights_iv_ar <- function(opt_intervals, # self
                          sample_target,
                          candidate,
                          nuisance,
                          translate_dirs,
                          translate_dirs_candidate) {

  score_sample = c()
  lognum = 0

  i = 1
  for (t in opt_intervals$opt_sampling_info) {
    opt_sampler = t[[1]]
    opt_sample = t[[2]]

    # these are now score coordinates
    sample_matrix = t(translate_dirs[[i]] %*% t(sample_target))
    score_sample = matrix(0, ncol = ncol(sample_matrix), nrow = nrow(sample_matrix))
    for (j in 1:nrow(sample_matrix)) {
      score_sample[j,] = sample_matrix[j,] + t(nuisance[[i]])
    }
    for (k in 1:nrow(score_sample)) {
      score_sample[k,] = score_sample[k,] + t(translate_dirs_candidate[[i]]*candidate)
    }

    logden = opt_sampler$log_density(score_sample, opt_sample)
    lognum = lognum + logden
    i = i + 1
  }

  logratio = lognum - opt_intervals$logden
  logratio = logratio - max(logratio)

  return(exp(logratio))

}


#' Test Coverage of Confidence Interval for AR Test Statistic
#'
#' Test selective confidence interval for AR test statistic with
#' instrumental variables.
#'
#' @param observed_target A vector of parameters, representing coordinates of the target
#' @param target_cov Covariance of the target (e.g. AR)
#' @param score_cov Covariance of the target score (e.g. AR score)
#' @param linear_func Linear function
#' @param gl_ar The group lasso object for AR test statistic representing the
#'              penalized convex optimization equation (generated by
#'              group_lasso_iv function)
#' @param opt_sampler Optimization sampler
#' @param beta_reference Reference value of beta parameter
#' @param beta_candidate Candidate value of beta parameter
#' @param sample_args Default to NULL (optional)
#' @param sample Represents a sample of the target. Allows reuse of the same sample
#'               for construction of confidence intervals, hypothesis tests, etc.
#' @param level Specify the confidence level (optional)
#'
#' @return TRUE if p-value is higher than the significance level (i.e. not
#'         significant) and FALSE otherwise
#' @export
#'
#' @references
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2019). Inference After Selecting
#' Plausibly Valid Instruments with Application to Mendelian Randomization.
#'
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2020). Inferring Treatment
#' Effects After Testing Instrument Strength in Linear Models.
#'
#' @seealso
#' \link{optimization_intervals} to initialize an interval for the optimization
#' problem, which specify the observed target and its covariance as well as
#' optimization samples and sampler. We need to initialize an optimization_intervals
#' before computing confidence intervals.
#'
#' \link{pivot_iv_ar} for calculating the pivot quantities of the optimization
#' intervals before computing p-values.
#'
#' \link{confidence_intervals_iv_ar} for constructing selective confidence
#' intervals for AR test statistic.
#'
#' \link{confidence_interval_iv_ar} for constructing a selective
#' confidence interval for a specific parameter of the target for AR
#' test statistic.
#'
#' @examples
#' # Fit the group lasso optimization model
#' Z = matrix(rnorm(10*3), nrow = 10, ncol = 3) +
#'     matrix(replicate(3, matrix(0, nrow = 10, ncol = 1)),
#'     nrow = 10)
#' errorTerm = MASS::mvrnorm(n=10, mu=rep(0,2),
#'             Sigma=rbind(c(1, 0.8),c(0.8, 1)))
#' D = Z %*% rep(1, 3) + errorTerm[1:10, 2]
#' Y = D * 1 + errorTerm[1:10, 1]
#' gl_ar <- group_lasso_iv_ar(Y, D, Z)
#' model_ar <- fit_ar(gl_ar)
#'
#' # Estimate covariance and obtain summary statistics
#' cov = estimate_covariance(Y, D, Z)
#' s <- summary_ar(gl_ar, model_ar$sampler,
#'                 Sigma_11=cov[1,1], Sigma_12=cov[1,2])
#'
#' # Test confidence interval coverage for AR test statistic
#' confidence_interval_coverage(observed_target=s$observed_target_tsls,
#'                              target_cov=s$cov_target,
#'                              score_cov=s$cov_target_score,
#'                              linear_func=s$K2,
#'                              gl_ar=gl_ar,
#'                              opt_sampler=model_ar$sampler,
#'                              beta_reference=s$two_stage_ls[1,1],
#'                              beta_candidate=0,
#'                              sample=s$opt_sample,
#'                              level=0.95)
confidence_interval_coverage <- function(observed_target,
                                         target_cov,
                                         score_cov,
                                         linear_func,
                                         gl_ar,
                                         opt_sampler,
                                         beta_reference,
                                         beta_candidate,
                                         sample_args=NULL,
                                         sample,
                                         level=0.95) {

  ndraw = dim(sample)[1]

  opt_sampling_info = list(sets::tuple(opt_sampler, sample, target_cov, score_cov))
  intervals = conditionalInference::optimization_intervals(opt_sampling_info,
                                                           observed_target,
                                                           ndraw)

  pvalue = conditionalInference::pivot_iv_ar(opt_intervals=intervals,
                                             linear_func=linear_func,
                                             parameter_reference=beta_reference,
                                             candidate=beta_candidate-beta_reference,
                                             gl_ar=gl_ar,
                                             alternative='greater')

  #print(pvalue)
  coverage = pvalue >= (1-level)

  return(coverage)
}


#' Confidence Intervals with Instrumental Variables for AR Test Statistic
#'
#' Construct selective confidence intervals for each parameter of the target.
#' The confidence intervals are computed for the optimization problem with
#' instrumental variables. We compute the confidence intervals of the
#' Anderson-Rubin (AR) test statistic.
#'
#' @param observed_target  A vector of parameters, representing coordinates of the target
#' @param target_cov Covariance of the target (e.g. AR)
#' @param score_cov Covariance of the target score (e.g. AR score)
#' @param linear_func Linear function
#' @param gl_ar The group lasso object for AR test statistic representing the
#'              penalized convex optimization equation (generated by
#'              group_lasso_iv function)
#' @param opt_sampler Optimization sampler
#' @param beta_reference Reference value for beta parameter
#' @param sample_args Default to NULL (optional)
#' @param sample Represents a sample of the target. Allows reuse of the same sample
#'               for construction of confidence intervals, hypothesis tests, etc.
#' @param level Specify the confidence level (optional)
#' @param how_many_sd Specify the number of standard deviations (optional)
#' @param how_many_steps Specify the number of steps (optional)
#'
#' @return The selective confidence intervals.
#' @export
#'
#' @references
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2019). Inference After Selecting
#' Plausibly Valid Instruments with Application to Mendelian Randomization.
#'
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2020). Inferring Treatment
#' Effects After Testing Instrument Strength in Linear Models.
#'
#' @seealso
#' \link{optimization_intervals} to initialize an interval for the optimization
#' problem, which specify the observed target and its covariance as well as
#' optimization samples and sampler. We need to initialize an optimization_intervals
#' before computing confidence intervals.
#'
#' \link{confidence_interval_iv_ar} for constructing a selective
#' confidence interval for a specific parameter of the target for AR
#' test statistic.
#'
#' \link{confidence_intervals_iv} for constructing selective confidence
#' intervals for TSLS test statistic.
#'
#' \link{confidence_interval_iv} for constructing a selective
#' confidence interval for a specific parameter of the target for TSLS
#' test statistic.
#'
#' @examples
#' # Fit the group lasso optimization model
#' Z = matrix(rnorm(10*3), nrow = 10, ncol = 3) +
#'     matrix(replicate(3, matrix(0, nrow = 10, ncol = 1)),
#'     nrow = 10)
#' errorTerm = MASS::mvrnorm(n=10, mu=rep(0,2),
#'             Sigma=rbind(c(1, 0.8),c(0.8, 1)))
#' D = Z %*% rep(1, 3) + errorTerm[1:10, 2]
#' Y = D * 1 + errorTerm[1:10, 1]
#' gl_ar <- group_lasso_iv_ar(Y, D, Z)
#' model_ar <- fit_ar(gl_ar)
#'
#' # Estimate covariance and obtain summary statistics
#' cov = estimate_covariance(Y, D, Z)
#' s <- summary_ar(gl_ar, model_ar$sampler,
#'                 Sigma_11=cov[1,1], Sigma_12=cov[1,2])
#'
#' # Construct confidence intervals for AR test statistic
#' confidence_intervals_iv_ar(observed_target=s$observed_target_tsls,
#'                            target_cov=s$cov_target,
#'                            score_cov=s$cov_target_score,
#'                            linear_func=s$K2,
#'                            gl_ar=gl_ar,
#'                            opt_sampler=model_ar$sampler,
#'                            beta_reference=s$two_stage_ls[1,1],
#'                            sample=s$opt_sample,
#'                            level=0.95,
#'                            how_many_sd=4000)
confidence_intervals_iv_ar <- function(observed_target,
                                       target_cov,
                                       score_cov,
                                       linear_func,
                                       gl_ar,
                                       opt_sampler,
                                       beta_reference,
                                       sample_args=NULL,
                                       sample,
                                       level=0.95,
                                       how_many_sd=20,
                                       how_many_steps=100) {

  ndraw = nrow(sample)

  opt_sampling_info = list(sets::tuple(opt_sampler, sample, target_cov, score_cov))
  intervals = conditionalInference::optimization_intervals(opt_sampling_info,
                                                           observed_target,
                                                           ndraw)


  conf_int = confidence_interval_iv_ar(intervals,
                                       linear_func,
                                       gl_ar,
                                       beta_reference,
                                       level=level,
                                       how_many_sd=how_many_sd,
                                       how_many_steps=how_many_steps)
  limits = c(conf_int)

  return(limits)
}


#' Confidence Interval with Instrumental Variables for AR Test Statistic
#'
#' Construct a selective confidence interval for a specific parameter of the target.
#'
#' @param intervals Optimization intervals
#' @param linear_func Linear function
#' @param gl_ar The group lasso object for AR test statistic representing the
#'              penalized convex optimization equation (generated by
#'              group_lasso_iv function)
#' @param beta_reference Reference value for beta parameter
#' @param level Specify the confidence level (optional)
#' @param how_many_sd Specify the number of standard deviations (optional)
#' @param how_many_steps Specify the number of steps (optional)
#'
#' @return A sequence of pivot quantities
#' @export
#'
#' @references
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2019). Inference After Selecting
#' Plausibly Valid Instruments with Application to Mendelian Randomization.
#'
#' Bi, Nan & Kang, Hyunseung & Taylor, Jonathan. (2020). Inferring Treatment
#' Effects After Testing Instrument Strength in Linear Models.
#'
#' @seealso
#' \link{optimization_intervals} to initialize an interval for the optimization
#' problem, which specify the observed target and its covariance as well as
#' optimization samples and sampler. We need to initialize an optimization_intervals
#' before computing confidence intervals.
#'
#' \link{confidence_intervals_iv_ar} for constructing selective confidence
#' intervals for AR test statistic.
#'
#' \link{confidence_intervals_iv} for constructing selective confidence
#' intervals for TSLS test statistic.
#'
#' \link{confidence_interval_iv} for constructing a selective
#' confidence interval for a specific parameter of the target for TSLS
#' test statistic.
#'
#' \link{test_stat} that returns the result of comparing parameter of
#' interest and observed target test statistic.
#'
#' \link{pivot_iv_ar} for calculating the pivot quantities of the optimization
#' intervals before computing p-values for AR test statistic.
#'
#' @examples
#' # Fit the group lasso optimization model
#' Z = matrix(rnorm(10*3), nrow = 10, ncol = 3) +
#'     matrix(replicate(3, matrix(0, nrow = 10, ncol = 1)),
#'     nrow = 10)
#' errorTerm = MASS::mvrnorm(n=10, mu=rep(0,2),
#'             Sigma=rbind(c(1, 0.8),c(0.8, 1)))
#' D = Z %*% rep(1, 3) + errorTerm[1:10, 2]
#' Y = D * 1 + errorTerm[1:10, 1]
#' gl_ar <- group_lasso_iv_ar(Y, D, Z)
#' model_ar <- fit_ar(gl_ar)
#'
#' # Estimate covariance and obtain summary statistics
#' cov = estimate_covariance(Y, D, Z)
#' s <- summary_ar(gl_ar, model_ar$sampler,
#'                 Sigma_11=cov[1,1], Sigma_12=cov[1,2])
#'
#'
#' # Construct the optimization intervals before computing confidence intervals
#' # for AR test statistic
#' opt_sampling_info = list(sets::tuple(model_ar$sampler,
#'                                      s$opt_sample,
#'                                      s$cov_target,
#'                                      s$cov_target_score))
#' intervals <- optimization_intervals(opt_sampling_info,
#'                                     s$observed_target,
#'                                     nrow(s$opt_sample))
#'
#' # Construct the confidence interval a specific observed AR test statistic
#' confidence_interval_iv_ar(intervals=intervals,
#'                           linear_func=s$K2,
#'                           gl_ar=gl_ar,
#'                           beta_reference=s$two_stage_ls[1,1],
#'                           level=0.95,
#'                           how_many_sd=4000,
#'                           how_many_steps=100)
confidence_interval_iv_ar <- function (intervals, # self
                                       linear_func,
                                       gl_ar,
                                       beta_reference,
                                       level=0.95,
                                       how_many_sd=20,
                                       how_many_steps=10) {

  sample_stat = conditionalInference::test_stat(gl_ar$Y,
                                                gl_ar$D,
                                                gl_ar$Z,
                                                beta_reference,
                                                intervals$normal_sample)

  grid_min = -how_many_sd * sd(sample_stat)
  grid_max = how_many_sd * sd(sample_stat)

  root <- function(gamma) {
    result = conditionalInference::pivot_iv_ar(intervals,
                                               linear_func,
                                               beta_reference,
                                               gamma,
                                               gl_ar,
                                               alternative='greater') - (1 - level)
    return(result)
  }

  betas = seq(from=grid_min, to=grid_max, length.out=how_many_steps)
  idx = 1
  for (beta in betas) {
    pivot = root(beta) + (1-level)
    if (idx == 1) {
      pivots = c(pivot)
    } else {
      pivots = c(pivots, pivot)
    }
    idx = idx + 1
  }

  return(pivots)
}

